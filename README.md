# Artificial Teaching Assistant (aTA)

Download c-REALM TF Hub model + encoded retrieval corpora: [link](https://storage.googleapis.com/rt-checkpoint/retriever.zip)

Place retriever folder under /models.

Download c-REALM tokenized KILT Wikipedia data: [link](https://storage.googleapis.com/rt-checkpoint/kilt_retrieval_train.zip)

Place retrieval_train folder under /models.

Citation

```bibtex
@inproceedings{lfqa21,
  author    = {Kalpesh Krishna and Aurko Roy and Mohit Iyyer},
  Booktitle = {North American Association for Computational Linguistics},
  Year      = "2021",
  Title     = {Hurdles to Progress in Long-form Question Answering},
}
```

```bibtex
@misc{roy*2020efficient,
    title   = {Efficient Content-Based Sparse Attention with Routing Transformers},
    author  = {Aurko Roy* and Mohammad Taghi Saffar* and David Grangier and Ashish Vaswani},
    year    = {2020},
    url     = {https://arxiv.org/pdf/2003.05997.pdf}
}
```
